{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from util.evaluation import SMAPE\n",
    "%matplotlib inline\n",
    "\n",
    "traffic=pd.read_csv('../data/cl_traffic.csv')\n",
    "\n",
    "traffic=traffic.fillna(0)\n",
    "\n",
    "traffic.head()\n",
    "\n",
    "sample_index=np.random.choice(traffic.index,400,replace=False)\n",
    "sample_series=[]\n",
    "for u in sample_index:\n",
    "#     print('Training...|| {:.2f}'.format(u/tot_len*100)+'%',end='\\r')\n",
    "    sample_series.append(traffic.loc[u][:-4].values)\n",
    "\n",
    "def diff(x,epsilon=1e-3):\n",
    "    return((x[1:]-x[:-1])/(x[:-1]+epsilon))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_and_clean(sample_series,train_start,train_end,test_len):\n",
    "    clean_series=[]\n",
    "    test_series=[]\n",
    "    for index in range(len(sample_series)):\n",
    "        c=np.array(sample_series[index][train_start:train_end])\n",
    "        test_series.append(sample_series[index][train_end:(train_end+test_len)])\n",
    "        std=np.std(c)\n",
    "        mean=np.mean(c)\n",
    "        c[(c-np.mean(c))>2*std]=mean+2*std\n",
    "        c[(c-np.mean(c))<-2*std]=mean-2*std\n",
    "        clean_series.append(c)\n",
    "    return (clean_series,test_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalize_X(clean_series):\n",
    "\n",
    "    recover_dic={}\n",
    "    scaled_series=[]\n",
    "    for i in range(len(clean_series)):\n",
    "        if np.sum(clean_series[i])==0:\n",
    "            scaled_series.append(np.zeros_like(clean_series[i]))\n",
    "            recover_dic[i]=(0,0)\n",
    "        else:\n",
    "            std=np.std(clean_series[i])\n",
    "            biased_mean=np.mean(clean_series[i])-3*std\n",
    "\n",
    "            recover_dic[i]=(std,biased_mean)\n",
    "            new_series=clean_series[i]-biased_mean\n",
    "            new_series[new_series<0]=0\n",
    "            new_series=new_series/(6*std)\n",
    "            new_series[new_series>1]=1\n",
    "            scaled_series.append(new_series)\n",
    "    return (scaled_series,recover_dic)\n",
    "\n",
    "\n",
    "def normalize_Y(clean_series,recover_dic):\n",
    "    scaled_series=[]\n",
    "    for i in range(len(clean_series)):\n",
    "        (std,biased_mean) = recover_dic[i]\n",
    "        \n",
    "        if std==0:\n",
    "            # ignore all zero cases\n",
    "#             print(clean_series[i])\n",
    "            scaled_series.append(np.zeros_like(clean_series[i]))\n",
    "\n",
    "        else:\n",
    "            \n",
    "\n",
    "            new_series=clean_series[i]-biased_mean\n",
    "            new_series[new_series<0]=0\n",
    "            new_series=new_series/(6*std)\n",
    "            new_series[new_series>1]=1\n",
    "            scaled_series.append(new_series)\n",
    "    return (scaled_series)\n",
    "\n",
    "def recover(scaled_series,recover_dic):\n",
    "    recovered_series=[]\n",
    "    for i in range(len(scaled_series)):\n",
    "        std,biased_mean=recover_dic[i]\n",
    "        new_series=scaled_series[i]*(6*float(std))+biased_mean\n",
    "        recovered_series.append(new_series)\n",
    "    return recovered_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa,dic=normalize_X(clean_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb=recover(aa,dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encode_start=0\n",
    "encode_end=150\n",
    "decode_len=63\n",
    "\n",
    "clean_series,decode_series = split_and_clean(sample_series,encode_start,encode_end,decode_len)\n",
    "train_x,train_dic = normalize_X(clean_series)\n",
    "train_y = normalize_Y(decode_series,train_dic)\n",
    "\n",
    "\n",
    "encode_start=200\n",
    "encode_end=350\n",
    "decode_len=63\n",
    "\n",
    "\n",
    "clean_series,decode_series = split_and_clean(sample_series,encode_start,encode_end,decode_len)\n",
    "\n",
    "test_x,test_dic = normalize_X(clean_series)\n",
    "test_y = normalize_Y(decode_series,test_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(np.concatenate((train_x[18],train_y[18]),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def X_loader(x,batchsize=10):\n",
    "    batch=0\n",
    "    x=np.array(x,dtype=np.float32)\n",
    "#     x=np.log(x+1)\n",
    "    \n",
    "    while batch<(len(x) // batchsize):\n",
    "        \n",
    "        data=x[batch*batchsize:(batch+1)*batchsize,:]\n",
    "        tensor=torch.FloatTensor(np.array(data, dtype=float))\n",
    "        tensor=tensor.unsqueeze(2).cuda()\n",
    "#         tensor=tensor.repeat(1,1,25)\n",
    "        yield(tensor)\n",
    "        batch+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def Y_loader(y,batchsize=10):\n",
    "    batch=0\n",
    "    y=np.array(y,dtype=np.float32)\n",
    "#     y=np.log(y+1)\n",
    "    \n",
    "    while batch<(len(y) // batchsize):\n",
    "        \n",
    "        data=y[batch*batchsize:(batch+1)*batchsize,:]\n",
    "        tensor=torch.FloatTensor(np.array(data, dtype=float))\n",
    "        tensor=tensor.unsqueeze(2).cuda()\n",
    "\n",
    "        yield(tensor)\n",
    "        batch+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru.weight_ih_l0 tensor([[ 0.5137],\n",
      "        [-0.4497],\n",
      "        [ 0.3978]], device='cuda:0')\n",
      "gru.weight_hh_l0 tensor([[ 0.5945],\n",
      "        [-0.1228],\n",
      "        [ 0.7839]], device='cuda:0')\n",
      "gru.bias_ih_l0 tensor([ 0.0366, -0.4584,  1.3032], device='cuda:0')\n",
      "gru.bias_hh_l0 tensor([ 0.3414, -0.9296,  1.3885], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in decoder.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + numpy.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.44152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19131007820695337"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=0.4\n",
    "h=1\n",
    "r1=-0.3818*x-0.6236-0.0479*h-0.6173\n",
    "print(r1)\n",
    "r=sigmoid(r1)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5494280370459982"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=sigmoid(-0.3851*x+0.6046+0.3549*x-0.4002)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22696\n",
      "1.6848443328167804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6876821322670081"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1=(0.1743*x+0.1921)\n",
    "print(n1)\n",
    "n2=(0.3714*x+1.5644+r*n1)\n",
    "print(n2)\n",
    "n=np.tanh(sigmoid(n2))\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8592783252699375"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out=(1-z)*n+z*h\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainx=X_loader(train_x)\n",
    "sample=next(trainx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2080]],\n",
       "\n",
       "        [[ 0.2724]],\n",
       "\n",
       "        [[ 0.3864]],\n",
       "\n",
       "        [[ 0.9286]],\n",
       "\n",
       "        [[ 0.4617]],\n",
       "\n",
       "        [[ 0.3999]],\n",
       "\n",
       "        [[ 0.3935]],\n",
       "\n",
       "        [[ 0.6377]],\n",
       "\n",
       "        [[ 0.5955]],\n",
       "\n",
       "        [[ 0.4381]]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[:,3:4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.]]], device='cuda:0')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.9619]],\n",
       " \n",
       "         [[ 0.9904]],\n",
       " \n",
       "         [[ 0.9972]],\n",
       " \n",
       "         [[ 0.9990]],\n",
       " \n",
       "         [[ 0.9996]],\n",
       " \n",
       "         [[ 0.9997]],\n",
       " \n",
       "         [[ 0.9997]],\n",
       " \n",
       "         [[ 0.9998]],\n",
       " \n",
       "         [[ 0.9998]],\n",
       " \n",
       "         [[ 0.9998]]], device='cuda:0'),\n",
       " tensor([[[ 0.9998]]], device='cuda:0'))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(sample[:,6:7,:],oo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SMAPE(true,predicted):\n",
    "    true=true.squeeze()\n",
    "    predicted=predicted.squeeze()\n",
    "#     true=torch.exp(true)-1\n",
    "#     predicted=torch.exp(predicted)-1\n",
    "    epsilon = 0.1\n",
    "    summ = torch.abs(true) + torch.abs(predicted) + epsilon\n",
    "    smape = torch.abs(predicted - true) / summ * 2.0\n",
    "    return torch.mean(smape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from numpy import random as random\n",
    "epoch=1\n",
    "indicator=20\n",
    "\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha=0.99, \\\n",
    "#     eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0)\n",
    "input_size=1\n",
    "hidden_size=1\n",
    "output_size=1\n",
    "lr=0.01\n",
    "\n",
    "encoder=EncoderRNN(input_size,hidden_size,output_size).cuda() if use_cuda else EncoderRNN(1,hidden_size)\n",
    "decoder=DecoderRNN(input_size,hidden_size,output_size).cuda() if use_cuda else DecoderRNN(1,hidden_size)\n",
    "teacher_forcing_ratio = 0\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=lr)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epoch):\n",
    "    trainx=X_loader(train_x)\n",
    "    trainy=Y_loader(train_y)\n",
    "    running_loss = 0.0\n",
    "#     validation(test_x,test_y)\n",
    "    for j,X_batch in enumerate(trainx):\n",
    "        #Parse loaded batch\n",
    "        x=X_batch\n",
    "        y=next(trainy)\n",
    "        (loss,oo)=train(x, y, encoder, decoder, encoder_optimizer, \\\n",
    "                  decoder_optimizer, SMAPE)\n",
    "        running_loss += loss\n",
    "\n",
    "        if (j>0) and (j % indicator == 0):\n",
    "            print(\"Epoch: {}; iterations: {}; Loss: {}\\n\".format(i, j, running_loss / indicator))\n",
    "            running_loss = 0.0\n",
    "    _,_,score = valid_iter(test_x, test_y)\n",
    "    print(\"Validation! Epoch: {}; Loss: {}\\n\".format(i, np.mean(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds,targets,scores=valid_iter(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.259035 25.032623 26.540068 26.56335  26.567204 26.567862 26.567972\n",
      " 26.567991 26.567995 26.567995 26.567995 26.567995 26.567995 26.567995\n",
      " 26.567995 26.567995 26.567995 26.567995 26.567995 26.567995 26.567995\n",
      " 26.567995 26.567995 26.567995 26.567995 26.567995 26.567995 26.567995\n",
      " 26.567995 26.567995 26.567995 26.567995 26.567995 26.567995 26.567995\n",
      " 26.567995 26.567995 26.567995 26.567995 26.567995 26.567995 26.567995\n",
      " 26.567995 26.567995 26.567995 26.567995 26.567995 26.567995 26.567995\n",
      " 26.567995 26.567995 26.567995 26.567995 26.567995 26.567995 26.567995\n",
      " 26.567995 26.567995 26.567995 26.567995 26.567995 26.567995 26.567995]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f11f809c198>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd8FVX6+PHPSQIJ0pIAhr4JvYYW\nQAVFQWmiWBDxS1eXVffr2lf0t8tGECsiooJfQFhUFARBkCpSRWlBQieQQIRACCUFAgSS3Of3x0wu\nCakXQkJunvfrldedOXNm5szhMs8950wxIoJSSqnSx6O4C6CUUqp4aABQSqlSSgOAUkqVUhoAlFKq\nlNIAoJRSpZQGAKWUKqUKFACMMb7GmHnGmP3GmH3GmNuNMf7GmJXGmIP2p5+d1xhjJhpjIo0xO40x\nbTNtZ6id/6AxZuiNOiillFL5K2gL4BNguYg0AVoB+4CRwCoRaQissucBegEN7b8RwGQAY4w/8B+g\nI9AB+E9G0FBKKVX08g0AxphKwF3AlwAicllEEoG+wEw720zgIXu6L/CVWDYBvsaYGkAPYKWIxItI\nArAS6FmoR6OUUqrAvAqQpx5wCphhjGkFbANeAAJEJBZARGKNMbfa+WsBRzOtH2On5Zaeq6pVq0pg\nYGABiqiUUirDtm3bTotItfzyFSQAeAFtgedFZLMx5hOudPfkxOSQJnmkZ13ZmBFYXUfUrVuXsLCw\nAhRRKaVUBmPMnwXJV5AxgBggRkQ22/PzsAJCnN21g/15MlP+OpnWrw0czyM9CxGZIiIhIhJSrVq+\nAUwppdQ1yjcAiMgJ4KgxprGd1A3YCywCMq7kGQostKcXAUPsq4FuA5LsrqIVQHdjjJ89+NvdTlNK\nKVUMCtIFBPA8MMsYUxY4BAzHCh7fG2OeAo4Aj9l5lwK9gUjggp0XEYk3xowBttr5RotIfKEchVJK\nKZeZm/lx0CEhIaJjAEq5h9TUVGJiYkhJSSnuorgNHx8fateuTZkyZbKkG2O2iUhIfusXtAWglFLX\nJSYmhooVKxIYGIgxOV0TolwhIpw5c4aYmBiCgoKuaRv6KAilVJFISUmhSpUqevIvJMYYqlSpcl0t\nKg0ASqkioyf/wnW99emWAeBI0hH+vfrfHEo4VNxFUUqpm5ZbBoDElETe/vVtth7bmn9mpVSpER0d\nTYsWLbKljxo1il9++SXX9X788Uf27t17I4tWLNwyADT0b4jBsP/0/uIuilKqBBg9ejT33ntvrsuv\nJQCkpaVdb7FuOLcMAOXKlCPQN5CIMxH55l18YDGX0y8XQamUUjeD9PR0/vrXv9K8eXO6d+/OxYsX\nGTZsGPPmzQNg5MiRNGvWjODgYF599VV+//13Fi1axGuvvUbr1q2JiooiPDyc2267jeDgYB5++GES\nEhIAuPvuu3nzzTfp0qULY8eOJSgoiNTUVADOnj1LYGCgc/5m4LaXgTap2iTfFsDOuJ088N0DfPPw\nNwwMHlhEJVNKvbj8RcJPhBfqNltXb82EnhPyzXfw4EG+++47pk6dSv/+/fnhhx+cy+Lj41mwYAH7\n9+/HGENiYiK+vr48+OCD9OnTh379+gEQHBzMp59+SpcuXRg1ahRvvfUWEyZY+05MTGTdunWA1eW0\nZMkSHnroIWbPns2jjz6a7Zr94uSWLQCAxlUaE3EmAoc4cs2TESCiEqKKqlhKqWIWFBRE69atAWjX\nrh3R0dHOZZUqVcLHx4enn36a+fPnc8stt2RbPykpicTERLp06QLA0KFDWb9+vXP5448/7px++umn\nmTFjBgAzZsxg+PDhN+KQrplbtwAupF4g5mwMdSvXzTHPwTMHAfgzsUAPzlNKFZKC/FK/Uby9vZ3T\nnp6eXLx40Tnv5eXFli1bWLVqFbNnz+azzz5j9erVLm2/fPnyzulOnToRHR3NunXrSE9Pz3EAuji5\nbQugSdUmAHl2A0UmRAIQnRRdFEVSSt3kkpOTSUpKonfv3kyYMIHwcKubqmLFipw7dw6AypUr4+fn\nx6+//grA119/7WwN5GTIkCE88cQTN92vf3DjANC4qvXw0ojTuQ8EZ7QAohOji6JISqmb3Llz5+jT\npw/BwcF06dKFjz/+GIABAwbw4Ycf0qZNG6Kiopg5cyavvfYawcHBhIeHM2rUqFy3OXDgQBISEnji\niSeK6jAKzG27gALKB1DZu3KeLYCD8VYAOJJ0hHRHOp4enkVVPKVUMQgMDGT37t3O+VdffTVbni1b\ntmRL69SpU7bLQDdt2pQt39q1a7OlbdiwgX79+uHr63sNJb6x3DYAGGNoUrUJe0/nfO3u2UtnOXn+\nJPX86nEo4RCxybHUrlS7iEuplHJnzz//PMuWLWPp0qXFXZQcuW0XEEBwQDA743aS0yOvI+Ot/v97\ng6ybP3LrBkq+nJxnN5JSSuXm008/JTIykkaNGhV3UXLk1gGgVUAr4i/Gc+zcsWzLMvr/762XewBw\niIO+s/sSMjWEi6kXsy1XSqmSzL0DQPVWAOw4sSPbsoz+/65BXYGcLwUd9/s4Vh9eTfLlZNb/uT7b\ncqWUKsncOgAEBwQDsCMuewDYf3o/tSvVpsotVQgoH5CtBXA5/TL/WfsfejfsjY+XD8sjlxdFkZVS\nqsi47SAwQCXvSgT5BuUYAHbE7aBVgNVCCPQNzHYvwP7T+0lJS2FQy0E4xMGyyGXcsecOki8nM7zN\nzXc9r1JKucqtWwBgtQKu7gJKSUth36l9tK5u3Q5ep3IdjiYdBeC1n19jyrYpznVaVW9Fz/o9iTgT\nQf95/Rm3cVzRHoBS6qZVoUIFAI4fP+58TlBuJkyYwIULF5zzvXv3JjEx8YaWLz9uHwBaBbTiwJkD\nnL983pm299Re0iXdGQBqVazlHCieHj6dTzZ/ws64nXh7etOoSiN6N+yNh7GqKs1x8z/iVSl17dLT\n011ep2bNms6niebm6gCwdOnSYr83wO0DQJfALgjC4AWDuZR2CcD5FMKMLqDalWqTfDmZE8kniL8Y\nz95Te1kRtYLmtzbHy8OLhlUasve5vTzW7DHSHa5/OZRSN4fo6GiaNGnC0KFDCQ4Opl+/fly4cIHA\nwEBGjx5N586dmTt3LlFRUfTs2ZN27dpx5513sn+/dUPp4cOHuf3222nfvj3//ve/s2w34zk/6enp\nvPrqq7Rs2dL51NCJEydy/Phx7rnnHu655x7Auint9OnTAIwfP54WLVrQokUL51NFo6Ojadq0abZH\nVxcmtx4DAOsqn4k9J/KP5f+g1vha9G/eH4DyZcpT378+YLUAADYe3ehcb9fJXQxvfaWvv3HVxpQr\nU05bAEoVhhdfhPDCfRw0rVvDhPwfMhcREcGXX35Jp06dePLJJ5k0aRIAPj4+bNiwAYBu3brxxRdf\n0LBhQzZv3sxzzz3H6tWreeGFF3j22WcZMmQIn3/+eY7bnzJlCocPH2b79u14eXkRHx+Pv78/48eP\nZ82aNVStWjVL/m3btjFjxgw2b96MiNCxY0e6dOmCn59fjo+uHjRo0HVW1BVuHwAAnu/4PI2rNmZG\n+Awmh03G03jSsXZHZ7dOrUpWANgUk/XW7oyriDJ4Gk/SRVsASpVkderUoVOnTgAMGjSIiRMnAlce\n45ycnMzvv//OY4895lzn0iWr9+C3335zvj9g8ODBvP7669m2/8svv/DMM8/g5WWdXv39/fMsz4YN\nG3j44YedTxF95JFH+PXXX3nwwQfzfHR1YSgVAQCge/3udK/fnVu8bmF6+HRn9w9kagHEWC2AdjXa\nsS12W5Y8AF4eXtoCUKowFOCX+o1ijMlxPuME7HA48PX1dT4JNL/1ryYi+ea5On9u8np0dWFw+zGA\nq03sNZH+zfszoMUAZ1rNijUBCDsehsHwfIfnqeRdyTlInMHTeOoYgFIl3JEjR9i40fqx991339G5\nc+csyytVqkRQUBBz584FrBP0jh3WVYGdOnVi9uzZAMyaNSvH7Xfv3p0vvvjC+U7g+Ph4IOsjpTO7\n6667+PHHH7lw4QLnz59nwYIF3HnnnYVwpPkrUAAwxkQbY3YZY8KNMWF2mr8xZqUx5qD96WenG2PM\nRGNMpDFmpzGmbabtDLXzHzTGDL0xh5S38mXLM6ffHO76y13OtHJlyuFfzp+LaRcJqBDAkFZDiHs1\nDr9yflnW1RaAUiVf06ZNmTlzJsHBwcTHx/Pss89myzNr1iy+/PJLWrVqRfPmzVm4cCEAn3zyCZ9/\n/jnt27cnKSkpx+0//fTT1K1bl+DgYFq1asW3334LwIgRI+jVq5dzEDhD27ZtGTZsGB06dKBjx448\n/fTTtGnTppCPOhciku8fEA1UvSrtA2CkPT0SeN+e7g0sAwxwG7DZTvcHDtmffva0X177bdeunRSV\nlpNaCqFIh6kdcs3zwrIXpNK7lYqsTEq5k7179xZ3EeTw4cPSvHnz4i5GocqpXoEwKcC5/Xq6gPoC\nM+3pmcBDmdK/ssuxCfA1xtQAegArRSReRBKAlUDP69h/ocoYCK5TqU6uebQFoJRyJwUNAAL8bIzZ\nZowZYacFiEgsgP15q51eCziaad0YOy239CyMMSOMMWHGmLBTp04V/EiuU+2K1rsA8goAOgagVMl2\n9QthSruCXgXUSUSOG2NuBVYaY3J/zZbV9XM1ySM9a4LIFGAKQEhISO7D44XM2QKorC0ApVTpUKAW\ngIgctz9PAguADkCc3bWD/XnSzh4DZD6L1gaO55F+U8i4FDTPFoCH3geglHIf+QYAY0x5Y0zFjGmg\nO7AbWARkXMkzFFhoTy8ChthXA90GJNldRCuA7sYYP/uKoe522k2hWbVmGAzNqjXLNY+Xh9Vgcoij\nqIqllFI3TEG6gAKABfaNDV7AtyKy3BizFfjeGPMUcATIuG1uKdaVQJHABWA4gIjEG2PGAFvtfKNF\nJL7QjuQ6darbiZiXY5z3BOTE01gvjU9zpFHWs2xRFU0ppW6IfFsAInJIRFrZf81FZKydfkZEuolI\nQ/sz3k4XEfm7iNQXkZYiEpZpW9NFpIH9N+PGHda1yevkD1daADoQrFTJk5iY6Hzujyv++9//cvz4\nld7qzA9xK+lK3Z3A18PT40oLQClVsuQWAPJ7/PPVAcCdlJpnARUGZwtAB4KVKnFGjhxJVFQUrVu3\npkyZMlSoUIEaNWoQHh7O0qVL6dOnj/MS0XHjxpGcnEyLFi0ICwtj4MCBlCtXzvkIiU8//ZSffvqJ\n1NRU5s6dS5MmTYrz0K6ZBgAXZB4DUEpdu+J4GvR7773H7t27CQ8PZ+3atdx///3s3r2boKCgXJ+y\n2a9fPz777DPGjRtHSEiIM71q1ar88ccfTJo0iXHjxjFt2rTCPZgiol1ALtAxAKXcR4cOHQgKCrqm\ndR955BHgxjyiuShpC8AFOgagVOEoxqdBO2U8/hnAy8sLh+PK5d0pKSl5rpvxmGZPT0/nUz9LIm0B\nuEDHAJQquXJ7HDNAQEAAJ0+e5MyZM1y6dInFixcXaL2STlsALtAxAKVKripVqtCpUydatGhBuXLl\nCAgIcC4rU6YMo0aNomPHjgQFBWUZ1B02bBjPPPNMlkFgd2Ekj7fRFLeQkBAJCwvLP2MRmbVzFoMW\nDOLA/x6gYZWGxV0cpUqUffv20bRp0+IuhtvJqV6NMdtEJCSXVZy0C8gFOgaglHInGgBcoGMASil3\nogHABToGoNT1uZm7nEui661PDQAu0PsAlLp2Pj4+nDlzRoNAIRERzpw5g4+PzzVvQ68CcoGOASh1\n7WrXrk1MTAxF+aY/d+fj40Pt2rWveX0NAC7QMQClrl2ZMmWu+c5bdWNoF5ALdAxAKeVONAC4QMcA\nlFLuRAOAC3QMQCnlTjQAuEDHAJRS7kQDgAt0DEAp5U40ALhAxwCUUu5EA4ALdAxAKeVONAC4QMcA\nlFLuRAOAC3QMQCnlTjQAuEDHAJRS7kQDgAt0DEAp5U4KHACMMZ7GmO3GmMX2fJAxZrMx5qAxZo4x\npqyd7m3PR9rLAzNt4w07PcIY06OwD+ZG0zEApZQ7caUF8AKwL9P8+8DHItIQSACestOfAhJEpAHw\nsZ0PY0wzYADQHOgJTDLG7lQvIXQMQCnlTgoUAIwxtYH7gWn2vAG6AvPsLDOBh+zpvvY89vJudv6+\nwGwRuSQih4FIoENhHERRyegC0jEApZQ7KGgLYALwT8Bhz1cBEkUk46dwDFDLnq4FHAWwlyfZ+Z3p\nOaxTImR0AWkLQCnlDvINAMaYPsBJEdmWOTmHrJLPsrzWyby/EcaYMGNM2M324oiMLiAdA1BKuYOC\ntAA6AQ8aY6KB2VhdPxMAX2NMxgtlagPH7ekYoA6AvbwyEJ85PYd1nERkioiEiEhItWrVXD6gG0lb\nAEopd5JvABCRN0SktogEYg3irhaRgcAaoJ+dbSiw0J5eZM9jL18t1ktAFwED7KuEgoCGwJZCO5Ii\noGMASil3cj2vhHwdmG2MeRvYDnxpp38JfG2MicT65T8AQET2GGO+B/YCacDfRUpWX4peBqqUcicu\nBQARWQustacPkcNVPCKSAjyWy/pjgbGuFvJmoZeBKqXcid4J7AJjDB7GQ7uAlFJuQQOAizyNp7YA\nlFJuQQOAi7w8vHQMQCnlFjQAuMjTQ1sASin3oAHARV4eXjoGoJRyCxoAXKRjAEopd6EBwEU6BqCU\nchcaAFykYwBKKXehAcBF2gJQSrkLDQAu0jEApZS70ADgIr0KSCnlLjQAuEjHAJRS7kIDgIt0DEAp\n5S40ALhIxwCUUu5CA4CLdAxAKeUuNAC4SMcAlFLuQgOAi3QMQCnlLjQAuEjHAJRS7kIDgIt0DEAp\n5S40ALhIxwCUUu5CA4CLdAxAKeUuNAC4SMcAlFLuQgOAi3QMQCnlLjQAuEjHAJRS7kIDgIt0DEAp\n5S40ALhIxwCUUu4i3wBgjPExxmwxxuwwxuwxxrxlpwcZYzYbYw4aY+YYY8ra6d72fKS9PDDTtt6w\n0yOMMT1u1EHdSDoGoJRyFwVpAVwCuopIK6A10NMYcxvwPvCxiDQEEoCn7PxPAQki0gD42M6HMaYZ\nMABoDvQEJhljPAvzYIqCjgEopdxFvgFALMn2bBn7T4CuwDw7fSbwkD3d157HXt7NGGPs9NkicklE\nDgORQIdCOYoi5GV0DEAp5R4KNAZgjPE0xoQDJ4GVQBSQKCIZP4VjgFr2dC3gKIC9PAmokjk9h3Uy\n72uEMSbMGBN26tQp14/oBtMWgFLKXRQoAIhIuoi0Bmpj/WpvmlM2+9Pksiy39Kv3NUVEQkQkpFq1\nagUpXpHSMQCllLtw6SogEUkE1gK3Ab7GGC97UW3guD0dA9QBsJdXBuIzp+ewTonhaTy1C0gp5RYK\nchVQNWOMrz1dDrgX2AesAfrZ2YYCC+3pRfY89vLVIiJ2+gD7KqEgoCGwpbAOpKh4eXhpF5BSyi14\n5Z+FGsBM+4odD+B7EVlsjNkLzDbGvA1sB760838JfG2MicT65T8AQET2GGO+B/YCacDfRUreT2lP\nD0/tAlJKuYV8A4CI7ATa5JB+iByu4hGRFOCxXLY1FhjrejFvHtoCUEq5C70T2EU6BqCUchcaAFzk\n5eGFQxxYwxpKKVVyaQBwkaeHdfOytgKUUiWdBgAXeXlYwyY6DqCUKuk0ALjI0358kV4JpJQq6TQA\nuEhbAEopd6EBwEU6BqCUchcaAFykLQCllLvQAOAiHQNQSrkLDQAu0haAUspdaABwkY4BKKXchQYA\nF2kLQCnlLjQAuEjHAJRS7kIDgIu0BaCUchcaAFykYwBKKXehAcBF2gJQSrkLDQAu0jEApZS70ADg\noowuIG0BKKVKOg0ALsroAtIxAKVUSacBwEUZXUDaAlBKlXQaAFxUrkw5AI6fO17MJVFKqeujAcBF\nITVDqO9Xn483fazvBVZKlWgaAFzk5eHFyM4jCTsexs9RPxd3cZRS6pppALgGQ1oNoU6lOjw+73E+\n2fSJtgSUUiWSBoBrUNazLCsHr6Rj7Y68uOJF1v+5vriLpJRSLtMAcI0aV23M/P7zqVi2IjN3zHRp\n3TRHGoPmD2Jt9NobUzillCqAfAOAMaaOMWaNMWafMWaPMeYFO93fGLPSGHPQ/vSz040xZqIxJtIY\ns9MY0zbTtoba+Q8aY4beuMMqGuXLluexZo8xd+9czl8+X+D1FkUsYtauWczfN/8Glk4ppfJWkBZA\nGvCKiDQFbgP+boxpBowEVolIQ2CVPQ/QC2ho/40AJoMVMID/AB2BDsB/MoJGSTas9TCSLyfz8aaP\nC3xvwMTNEwE4nHj4RhZNKaXylG8AEJFYEfnDnj4H7ANqAX2BjL6PmcBD9nRf4CuxbAJ8jTE1gB7A\nShGJF5EEYCXQs1CPphh0rtuZTnU68e81/6bVF624kHohy/Kvd3zNVzu+AmD+vvm8suIV1v25Di8P\nLw4lHCqOIiulFODiGIAxJhBoA2wGAkQkFqwgAdxqZ6sFHM20Woydllv61fsYYYwJM8aEnTp1ypXi\nFQtjDOuGrWPmQzPZe2ovX4R94VzmEAevrXyNF5a/QOy5WJ744QnGbxpP9QrVGRw8mMMJh/UKIqVU\nsSlwADDGVAB+AF4UkbN5Zc0hTfJIz5ogMkVEQkQkpFq1agUtXrHy9PBkSKsh3FvvXt7/7X3neMDO\nuJ3EnY8jMSWRgfMHcjn9MuF/C+f4y8dpW6MtF9MuEnc+rphLr5QqrQoUAIwxZbBO/rNEJGPkMs7u\n2sH+PGmnxwB1Mq1eGzieR7rbeOvutzh5/iRtp7Tlv+H/ZXnkcgCqlKvCmug1tK3RllbVW2GMoZ5f\nPQAOJxTOOMCGIxs4knSkULallCodCnIVkAG+BPaJyPhMixYBGVfyDAUWZkofYl8NdBuQZHcRrQC6\nG2P87MHf7naa27ijzh3M6TeHSt6VGL5wOJ9t+YzW1VvzZJsnAXiy9ZPOvEG+QQD5jgNcTr+cbzdR\n8uVk7vv6PkLXhl7fASilSpWCtAA6AYOBrsaYcPuvN/AecJ8x5iBwnz0PsBQ4BEQCU4HnAEQkHhgD\nbLX/RttpbqV/8/6sH7ae5tWac+zcMXrU78E/Ov6Dp9o8xeBWg535An0DgbyvBEpzpNFgYgNG/DQi\nzyCwPHI5KWkpHDhzoNCOQynl/rzyyyAiG8i5/x6gWw75Bfh7LtuaDkx3pYAlUbky5ZjTbw6Pz3uc\nJ1o8Qe1KtZn24LRseWpUqJFnC2Dj0Y0cPXuUadun0b5We0a0G5FjvgX7FwAQlRBVeAdRTObumcvR\ns0d5+faXi7soSrk9vRP4Bml+a3N2P7ebVtVb5Zqnnl+9PFsAiw8sxsvDi65BXfnHsn/kGCwup19m\nyYEleHl4cSL5BMmXkwul/MVlzPoxjF43Wq+OUqoIaAAoRkF+Qew7tY9LaZdyXL7k4BLu+stdfP3w\n15TxLMNLK17Klmdt9FqSLiUxoMUAIP8xhR0ndrD75O7rL7zt7KWznL2U10VhBRd7LpZdJ3eRdCmJ\no2eP5r+CUuq6aAAoRo83f5y483E5ntijE6PZc2oPfRr2oWbFmoy6axSLIhbx4/4fs+RbenApPl4+\nPNPuGQAi4yNz3d+F1AvcPfNuWk5uycD5AwvlxfaPfv8o/ef2v+7tAPxy6Bfn9M64nYWyTVX43nkH\nvvmmuEuhCoMGgGLUp1Ef/nnHP5kcNpklB5Y401PTU3n151edeQBeuO0F2tZoy9Afh2YZ7F0WuYy7\nA++mxa0tgLwDwA97fyAxJZHu9bvz7a5v2Xd6X6550xxppKan5ln+1PRUNhzZwNrotbm2Ylyx8tBK\nKntXBoo+AJy5cIYNRzYU6T5LqlmzYMGC4i6FKgwaAIrZ2G5jqVWxFp9v/RyAY2ePcf+39/PDvh8Y\n3308Das0BKxHUM/vP5+ynmUZvMC6muhQwiEOnDlArwa9qOxTmaq3VCUqPveB4Gnbp9HAvwEfdf8I\ngPAT4Tnm231yN0GfBDFs4bA8y74zbicpaSlcSr/ElmNbXD30LESEXw79Qo8GPQjyDSryADDu93Hc\nM/Mezl06V6T7LYlq1IDY2OIuhSoMGgCKmZeHF8NbD2d55HJm7ZxFs0nN2HBkA9MemMZLt2ftGvqL\n7194o/MbbDm2hUMJh5w3mvVsYD1SqYF/AyITcm4BHDhzgPV/ruepNk/RpGoTfLx8sgWAnXE7Gbxg\nMJ2mdyLmbAxz98wlMSUx17JvPrbZOV2QdyJsO76NUWtGZXteElgtl9jkWLoFdSM4ILjIA0DEmQjS\nHGm5BsWrnb5wulC60Eqi6tXhxIniLoUqDBoAbgJPtX0KgEELBlGzYk12PbvLmXa1h5pYz9z7cf+P\nLIxYSD2/ejT0t1oJ9f3q59oCmLh5ImU8yjCs9TC8PLxoeWtLwk+EszlmM+M3Wvf3/fWnv7IoYhG9\nGvTi+37fk+pIzTbmkNmWY1u4tfyttLi1BeuP5B4A0h3pPLfkOUKmhjBm/Rjm7pmbLc8fsX8A0L5m\ne4IDgok4E0FKWkqu2yxsGV1n22K35Zv3YupF6k+sz2dbPrvu/e45uYee3/QstIH0opDRAtALtUo+\nDQA3gUDfQB5s/CB1K9fl50E/U9+/fq556/nVIzggmA9//5Cfo37mqTZPYd2sDY2qNOJI0hGOJmW9\ngib+YjwzwmcwMHgg1StUB6B19dZsP7Gdl1a8xCs/v0LY8TC2HtvKK7e/wux+s+nXrB+BvoHM2TMn\n17JsPraZjrU60uUvXfjtyG85Pg7bIQ6G/DiEyWGTeem2l6hZsSaLDizKlu+P2D8o61mW5rc2Jzgg\nGIc42HNyT4Hq73qJiPPqqYIEgEMJhzh76Szr/lx33ftecnAJK6JWsOrQquveVlGpXh1SUiApqbhL\noq6XBoCbxOx+sznwvweoU7lOvnkfbvIwJ5JP0MC/Aa/c/oozfWiroXh7eTNy1cgs+adsm8KF1Au8\ndNuVLqU21dsQfzGejTEbAXh2ybMIQo/6PQDrKaf9m/VnZdRK3v313Wy/UJNSkth/er8zAJxPPc+m\nmE2AdWlouyntmLx1MjPDZ/Ltrm8Z23Us43uM58FGD7IickW2X/fbYrfR8taWlPUsS6sA696JvLpj\nRKTQumDizsdxPtV6gF/Y8bD9RSe8AAAX6klEQVR882fccFeQYAFWWS+mXsxxWcTpCABWHS45AaBG\nDetTu4FKPg0ANwkfLx+8vbwLlHdAiwFU9q7MpN6TsqzzF9+/8Ortr/Ltrm9ZfXg1YF3d8uHvH9Kj\nfg+CA4KdeVtXbw2At6c3Tas2Jex4GP7l/AmpGeLM8/LtL3NvvXt5c/WbtJ/a3nmyAvh408cAdA3q\nSs8GPfH29HZ27YzfOJ4/Yv/gxRUv8vovr9OxVkfe6PwGAA82fpDzqedZc3iNc1siwh+xf9C2hvXy\nuPr+9ansXTnPk/Gbq96k1Ret8g0Cb69/m+aTmuMQR655MrrNbqt9GxGnI/IdCM5oLRxJOsKp8/k/\nsvzt9W9Td0LdHB/8F3HGqtOMf6+SoLrViNSBYDegAaAEalK1CQmvJ3Bf/fuyLXu98+s0qtKIB757\ngFk7ZzHyl5EkpiTy4X0fZsnXMqAlnsaTfs36OR9W171+dzw9PJ15AioEsHzQctYOXUvCxQQ6z+hM\n8uVkdsXt4p1f32Fgy4HcXud2KnpXpFfDXszbN4+T50/y0caP6F6/O34+fpy6cIrxPcY7u6nuCbqH\n8mXKO1+HuTJqJev/XE9CSgLtarQDwMN40LZGW8Jicw8ASyOXsufUHn468FOueVLSUpiwaQJ7T+3N\nszWR0f//ePPHESTfgeDM4ywFaQXM2zeP0xdO88j3j2RrCUSciaCsZ1n2nd7H8XM378Nxd8XtYnvs\ndkBbAO5EA0AJlXFCvVqFshVYP2w9jas0ZtCCQUzbPo3nQp6jZUDLbPlWDl7Jxz0+5vHmj3NLmVvo\n17RfjtvsEtiFH/r/wOkLp/l+z/e8uOJFKvtUZkLPCc48/Zv15/i543Se3pmLqReZ0GMCS/5nCdMf\nnM4dde5w5vPx8uHx5o/zza5v+DnqZ7p/051uX1mPlMpoAQCE1AxhZ9xOLqdfzlaec5fOOe9m/mTz\nJ7nW0dw9czlz8QyA84qpDDFnYzhzwVoWlRCFh/HgsWaP4WE8+OD3D/K8ByIqIYr6ftY4TX5dRsfP\nHWdn3E561O9B+InwLOWNvxjP6Qun6dfMqvfMraKbzfCFwxnwg3W3ubYA3IcGADcUUCGA35/6nZ8H\n/cyk3pN49953c8x3T9A9VCtfjTqV63D6tdM82uzRXLfZuW5nmlVrxpur3mT14dX8685/UfWWqs7l\nfRr1wcfLhyNJR5jdbzZNqzWlXc12DG8zPNu2Xr3jVS6lXaLv7L74l/OnZsWaeHt6ZwlSITVDuJx+\nOcfHVoQdD8MhDroGdWVt9FrnL9OrTQ6bTKMqjWhTvQ3LIpdlWdZ7Vm9u//J2klKSiEqIom7lutSq\nVItPe33K4gOL+etPf821LqISomhTow2NqzRm/Z/rWRe9jg1HNjDyl5E0/LQh3+36jsUHFvPaz6+x\nYJ91x9QH931A16CuTNo6yTlYnnFDX/9m/fEv58/SyKW57nNn3E4afdqIPxP/zDXPtTh/+Xyu4xMZ\nElMS2X5iOwfOHODY2WP4+oK3t7YA3IEGADfl4+XDffXv49n2z1KhbIV885crUy7P5cYYRrQdQdz5\nOGpVrMXfQv6WZXlF74osGrCITU9vcv6izU3Tak3p26QvKWkp/Puuf7P1r1v57cnf8PHycebJ6A7a\ndjx7F0vGwPXUB6ZSpVwVXlj+QraHxx07e4yNMRsZ3no4vRv2ZuPRjc57GuIvxrPr5C4Oxh9k4PyB\n7Izb6fxF/1z753jtjteYuWMm+0/vz7bvdEc6hxMOU9+vPu1rtWfloZXcPfNu7pxxJx/89gEOcfA/\n8/+HB757gHEbx/HiihepUaEGLW9tyfMdnufo2aP8FGF1W2WMqTSt1pRHmz7Kwv0LnW+Tu9qyg8s4\nGH+Q6dsL72G6DnFw54w7eeC7B/LMt+HIBucYyproNRhjtQK0BVDyaQBQBTa41WBqVqzJO93eyXKy\nznBf/fucg8v5ea/be7zQ8QWeDXmWgAoBtKvZLsvyen718PXxZUb4DL7d9W2WQdxNMZtoUrUJ9fzq\n8f697/PrkV/5asdXWdbPGFTtUb8HPRv0JF3S+WHvDwDOu5b7N+/PkoNL2H1yNw38GzjXfeX2Vyjr\nWTbH6/xjzsaQ6kilvl993r7nbb588EtWDl7JikEriPjfCPb/fT/vdnuXSb0n8VH3j0hzpNGzQU+M\nMfRp1Ie6levy8aaPEREizkTg5eFFkG8QA1sO5HzqeRZGLMy2T4A/Tlj3SczcMTPPAW1XfL/ne7af\n2M6qw6tyDLQZ1kWvo6xnWXx9fJ31WqOGtgDcgojctH/t2rUTVXr9Y+k/xHuMtxCKPLv4WYk9Fyvz\n984X//f9ZdiPw0REJN2RLrdPu12qfVBNzlw4Iz9F/CS743bL0AVDpcr7VSTdkS7pjnTpMLWDVPug\nmpw+f1pGrR4lHm95yNmUs3LwzEH5fMvnEnkmMsu+hy4YKuXHlpeEiwlZ0lcdWiWEIqsOrSrQMfwU\n8ZPEJcc55z/f8rkQiizYt0AemfOINPq0kfM46oyvI/fPuj/H7TSY2EAqvVtJCEXWHF7jTD+bclb2\nn9rvnD9x7oQMmDdAZmyfIWsOr5ElB5aIw+GQpQeWyvNLn5fU9FQREUlNT5XGnzaWJp81kQrvVJBB\n8wflegztp7SXO6ffKQ/PflgCJwSKiMhDD4k0b34lz4kTIvfeKzJpkojDUaCqUTcQECYFOMcW+0k+\nrz8NACotPU1e+/k1IRTnn/cYb1m0f5EzT3hsuHi+5SmtJrcSQpHACYFS66Na0u/7fs48O07sEK/R\nXjJ4/mDp/nV3CZ4cnOd+t8duFxNqZND8QeLIdEabEjZFCEWiE6Kv6XhS01Ol+efNxe89P+f2M7y+\n8nXxfMtTDicczrJOUkqSEIq8+cubUundSjJ4/mDnsmE/DhOv0V6y7OAyERF599d3s9QVocgjcx4R\nn7d9hFBk1OpRIiIyYeMEIRT5Ye8P8sKyF8RrtJccO3ssW3lPnz8tHm95yL9W/Us+3fypEIocij8k\nzz4r4u9v5XE4RPr0sc4mIPLkk3nXgcMh8ssvIk8/LdK6tcjOnQWru4MHrT+VPw0Aym04HA6Zum2q\nfLDhA/ntyG+SkpqSLc9Ly18SQpEOUzs4T3yTt07OkmfU6lFCKOI12ktGLBqR737fWvuWEIpM2jLJ\nmTb8x+Hi956fpKWnXfPxrDq0SsqMLiMjFo2QsylnnelHEo9ImdFl5JmfnhERka3HtkrLSS3l7XVv\nC6HIkgNL5LnFz4n3GG85df6UXEq7JL7v+QqhyC1jb5Hw2HBp80Ub6TC1g6yLXifLDi6TN355QwhF\ngiYESb/v+4nHWx4yavUouWXsLdLrm17icDgkKj5KTKiRN395M0s5ky8lyx1f3iFlRpeRP47/IftO\n7ZNH5zwqe0/ulbfess4eyckiEyda0xMmiPz97yLGiBw5kvOxp6SI3H67lb9SJRFvb5EhQ/Kur/Pn\nRUaNEvHyEqlXT1sYBaEBQJUqFy5fkDm758iltEvy6JxHhVAk4nREljyX0y5Lx6kdhVBk+h/T891m\nuiNden3TSzzf8pSF+xeKw+GQmh/VlMe+f+y6y5tTEBMRGbFohJQdU1Zm7ZwlAR8GZPklH3suVnbH\n7RZCkfc3vC/LDy4XQpGp26ZKwIcB0mBiAyEU+ej3j7Js86eInyQ6IVrOppyVe7+6VwhFKrxTQf5M\n/NOZ5+HZD4v/+/5y/vL5LGXxeMtD5u6Zm62cq1ZZZ4927UQ8PEQeeEAkPV3k0CErffTonI/755+t\n5W+/LXLxosizz1pB4PTpnPPPnStSo4a1TnCw9bl1a/Z84eEi//d/OW8jP6dOibz0ksgnn1zb+iI3\nX1DSAKBKrdPnT8u8PfNyXBYVHyWPznk0S798Xs5dOicdpnYQ7zHeMnvXbCEUmbZtWmEWN4vDCYel\n7JiyQihS+d3KMu63cUIoUmNcDWeeLjO6SN2P68pDsx+SCu9UkIupF51lI5QsJ/ac7Dm5R3bF7cqS\ntj56fZbWTuy5WCk7pqyzNZKTadOsX/vt21stgQzduonUqWONCTz9tEhcnEj//iJz5oj84x8iPj7W\nr3oRq/sHRMaNy7pth8P61Q/W9n/9VeTMGasV8M9/Zs37558i1apZeVesyPPQs4mJEala1Vr3lltE\nzp1zbX0RkZMnRRo1so7tZqEBQKlCEpccJ77v+Tr70Y8mHb2h+zuSeES2HtsqJ5NPiojIkz8+KS8t\nf8m5fNWhVXLL2FuEUOTxuY+LiNVN9sicR6T7192vaZ8Oh0M6T+8s/u/7S+y5WPnXqn+JCTVy4PSB\nPNcLDxc5ezZr2qxZ1pnFz+/KiRVEbr1VJDBQpHfvrPm7dBGpUEFkw4YraePGWesMHy5y6dKV9B49\nRIKCrvzijo0VadVKpGJFkbp1RVq0EElzoXfu7bet/WR0Y82cWfB1RaxWT/fu4hz/mDLFtfUzu3RJ\n5PLla18/Mw0AShWiTzZ9IoQizT9vnn/mInDs7DH5f6v+X5Zf8g6HI8uAtav2n9ov3mO8pdnnzaT8\n2PLy0OyHrmk76ekiixdbgWHiROvE/M47V06Sn3+eNf/x49Yv6IoVRX77TeTbb62WRb9+1rYymzbN\n2ka3btZ4Q506VoBZscLqLgKRr77KuVxbt1oBI4PDIdKwoRWAHA5rfKFbt7yPLTX1SutFxOp2ApHJ\nk63g5OlplbEgdfT88yIbN15J69tXpHp1q6X03Xeut2Yy0wCgVCG6nHZZus7sKuN/H1/cRbmhPtv8\nmVT9oKo89v1jcij+UKFuu1s364wTHZ19WUyMdTIuV87Kc+edWU+0GS5fFvnPf0QaN7auQmrdWuSP\nP6xlGSf0u+/Ovl5KitXKaNr0Sovl11+tfc2YYc2HhlqBZ/PmrOtu3Cjy3/+KJCVZYx7Nmlm/1lNT\nrdZIhw7Wvs+eFenZU5xjIHnF4qVLrXzNm1stloyxk4zWEog8+GB+NZo7DQBKqZtKVJTI9DzG3o8d\nE2nTRuSJJ6wB4msxZox1Vjt82JrPOAmvXHnlxNqihUhAwJUTbkZAiI21uqgqVhTp2tX6NZ5xxRKI\nVKlyZfqTT6yWCogsWHBl/5cviwwdaqX/619X0tPTRfbtuzJ///0iZcta+b780sprjMiBAyKLFlld\na5m7vlylAUApVeocPmyd1caMsU7+Dz8s8tRTIi+/bJ1w33lHpGZNkYEDRcaOFVm3Luv6MTHWSb9J\nEytPSIjI669bN7j5+VndV127Wq2JjBbF1d1U6enW4DdY3UEOh8jf/mbNv/SS1cIwxjrpd+xoBaFK\nlUR69Sq8eii0AABMB04CuzOl+QMrgYP2p5+dboCJQCSwE2ibaZ2hdv6DwNCCFE4DgFLKVffcY/16\n/+KLK7/Y/f2tq5KuR0ZrYscOq6tp+HCR/ftzzpuaKnLffSJlylhdRCDStu2V8pQrJ3L0qNUdNnSo\nFUyup8//agUNAMbKmztjzF1AMvCViLSw0z4A4kXkPWPMSDsAvG6M6Q08D/QGOgKfiEhHY4w/EAaE\nAAJsA9qJSEJe+w4JCZGwsPzf0KSUUhl27IA77oALF6BxY0hMhLg4+OgjePnloitHQgK8+SZs2wZ3\n3gkffgjz50N8PNx7L9Srd+P2bYzZJiIh+ebLLwDYGwsEFmcKABHA3SISa4ypAawVkcbGmP+zp7/L\nnC/jT0T+ZqdnyZcbDQBKqWsxdy4MHQrz5kFMDDz3HOzbBw0bFnfJikZBA4DXNW4/QERiAewgcKud\nXgvI/EbyGDstt3SllCp0jz0GfftC2bLWfN++EBBQvGW6GRX246Bzek2V5JGefQPGjDDGhBljwk6d\nyv99q0oplZOMkz/oyT831xoA4uyuH+zPk3Z6DFAnU77awPE80rMRkSkiEiIiIdWqVbvG4imllMrP\ntQaARVhX9WB/LsyUPsRYbgOS7K6iFUB3Y4yfMcYP6G6nKaWUKib5jgEYY77DGsStaoyJAf4DvAd8\nb4x5CjgCPGZnX4p1BVAkcAEYDiAi8caYMcBWO99oEYkvxONQSinlogJdBVRc9CogpZRyXUGvAtJ3\nAiulVCmlAUAppUopDQBKKVVKaQBQSqlSSgOAUkqVUhoAlFKqlNIAoJRSpZQGAKWUKqU0ACilVCml\nAUAppUopDQBKKVVKaQBQSqlSSgOAUkqVUhoAlFKqlNIAoJRSpZQGAKWUKqU0ACilVCmlAUAppUop\nDQBKKVVKaQBQSqlSSgOAUkqVUhoAlFKqlNIAoJRSpZQGAKWUKqU0ACilVCmlAUAppUqpIg8Axpie\nxpgIY0ykMWZkUe9fKaWUxasod2aM8QQ+B+4DYoCtxphFIrK3KMuhlLpOSUkQHg4XLoDDUdylcU81\nakDbtjd0F0UaAIAOQKSIHAIwxswG+gIaAJQqCUSgZ09YvRrS0oq7NO7t8cdh9uwbuouiDgC1gKOZ\n5mOAjpkzGGNGACMA6tatW3QlU0rlzxho1AjatYMuXaByZfD0LO5SuSd//xu+i6IOACaHNMkyIzIF\nmAIQEhIiOeRXShWnTz8t7hKoQlLUg8AxQJ1M87WB40VcBqWUUhR9ANgKNDTGBBljygIDgEVFXAal\nlFIUcReQiKQZY/4XWAF4AtNFZE9RlkEppZSlqMcAEJGlwNKi3q9SSqms9E5gpZQqpTQAKKVUKaUB\nQCmlSikNAEopVUoZkZv3XitjzCngz+vYRFXgdCEVx91o3eRN6ydvWj95K+76+YuIVMsv000dAK6X\nMSZMREKKuxw3I62bvGn95E3rJ28lpX60C0gppUopDQBKKVVKuXsAmFLcBbiJad3kTesnb1o/eSsR\n9ePWYwBKKaVy5+4tAKWUUrkosQHAGFPHGLPGGLPPGLPHGPOCne5vjFlpjDlof/rZ6cYYM9F+F/FO\nY8yNfddaMcujfkKNMceMMeH2X+9M67xh10+EMaZH8ZX+xjLG+Bhjthhjdth185adHmSM2Wx/d+bY\nT6zFGONtz0faywOLs/w3Wh71819jzOFM353Wdnqp+r+VwRjjaYzZboxZbM+XvO+PiJTIP6AG0Nae\nrggcAJoBHwAj7fSRwPv2dG9gGdZLaW4DNhf3MRRT/YQCr+aQvxmwA/AGgoAowLO4j+MG1Y0BKtjT\nZYDN9nfie2CAnf4F8Kw9/RzwhT09AJhT3MdQTPXzX6BfDvlL1f+tTMf9MvAtsNieL3HfnxLbAhCR\nWBH5w54+B+zDeuVkX2CmnW0m8JA93Rf4SiybAF9jTI0iLnaRyaN+ctMXmC0il0TkMBCJ9Q5nt2N/\nB5Lt2TL2nwBdgXl2+tXfnYzv1DygmzEmp7fbuYU86ic3per/FoAxpjZwPzDNnjeUwO9PiQ0AmdlN\nqjZYv1QCRCQWrJMgcKudLaf3Eed1QnQbV9UPwP/aTfXpGV1klLL6sZvv4cBJYCVWiydRRDLedJ75\n+J11Yy9PAqoUbYmL1tX1IyIZ352x9nfnY2OMt51Wqr47tgnAPwGHPV+FEvj9KfEBwBhTAfgBeFFE\nzuaVNYc0t78EKof6mQzUB1oDscBHGVlzWN1t60dE0kWkNdZrSTsATXPKZn+WqrqB7PVjjGkBvAE0\nAdoD/sDrdvZSVT/GmD7ASRHZljk5h6w3/fenRAcAY0wZrJPbLBGZbyfHZTQ/7c+Tdnqpex9xTvUj\nInH2f24HMJUr3Tylrn4ARCQRWIvVd+1rjMl4SVLm43fWjb28MhBftCUtHpnqp6fdrSgicgmYQen9\n7nQCHjTGRAOzsbp+JlACvz8lNgDYfWhfAvtEZHymRYuAofb0UGBhpvQh9hULtwFJGV1F7ii3+rmq\nb/ZhYLc9vQgYYF+xEAQ0BLYUVXmLkjGmmjHG154uB9yLNUayBuhnZ7v6u5PxneoHrBZ7RM8d5VI/\n+zP9sDJY/duZvzul5v+WiLwhIrVFJBBrUHe1iAykJH5/insU+lr/gM5YzaidQLj91xurb20VcND+\n9LfzG+BzrL7eXUBIcR9DMdXP1/bx78T6YtbItM7/s+snAuhV3MdwA+smGNhu18FuYJSdXg8r6EUC\ncwFvO93Hno+0l9cr7mMopvpZbX93dgPfcOVKoVL1f+uqurqbK1cBlbjvj94JrJRSpVSJ7QJSSil1\nfTQAKKVUKaUBQCmlSikNAEopVUppAFBKqVJKA4BSSpVSGgCUUqqU0gCglFKl1P8HT6DvKo55hsMA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f12a02a3668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ID=40\n",
    "source=sample_series[ID][encode_start:encode_end]\n",
    "pred=preds[ID]\n",
    "truth=targets[ID]\n",
    "print(pred)\n",
    "# for i in range(10):\n",
    "plt.figure()\n",
    "plt.plot(np.arange(encode_start,encode_end),source,color='g',label='history')\n",
    "plt.plot(np.arange(encode_end,encode_end+decode_len),pred,color='r',label='prediction')\n",
    "plt.plot(np.arange(encode_end,encode_end+decode_len),truth,color='b',label='truth')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid_iter(test_x,test_y):\n",
    "    testx=X_loader(test_x)\n",
    "    testy=Y_loader(test_y)\n",
    "\n",
    "    preds=[]\n",
    "    targets=[]\n",
    "\n",
    "    scores=[]\n",
    "    for j,X_batch in enumerate(testx):\n",
    "        #Parse loaded batch\n",
    "        print(j,end='\\r')\n",
    "        target=next(testy)\n",
    "        score,out = valid(X_batch, target, encoder, decoder, SMAPE)\n",
    "        out=out.T\n",
    "        scores.append(score)\n",
    "        target=target.squeeze().detach().cpu().numpy()\n",
    "        if j ==0:\n",
    "            preds=out\n",
    "            targets=target\n",
    "        else:\n",
    "            preds=np.concatenate((preds,out),axis=0)\n",
    "            targets=np.concatenate((targets,target),axis=0)\n",
    "    return (preds,targets,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda=True\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,output_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size)\n",
    "#         self.out = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, input, hidden):\n",
    "\n",
    "        output, hidden = self.gru(input, hidden)\n",
    "#         output = self.out(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        \n",
    "#         nn.init.xavier_normal_(self.out)\n",
    "        paras= nn.init.xavier_normal_(torch.empty(1,1,self.hidden_size)).cuda() if use_cuda else \\\n",
    "                nn.init.xavier_normal_(torch.empty(1,1,self.hidden_size))\n",
    "        return paras\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size,hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size)\n",
    "#         self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "\n",
    "        output, hidden = self.gru(input, hidden)\n",
    "#         output = self.out(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        paras= nn.init.xavier_normal_(torch.empty(1,1,self.hidden_size)).cuda() if use_cuda else \\\n",
    "                nn.init.xavier_normal_(torch.empty(1,1,self.hidden_size))\n",
    "        return paras\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, \\\n",
    "          decoder_optimizer, criterion):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[1]\n",
    "    target_length = target_variable.size()[1]\n",
    "    \n",
    "    encoder_outputs = torch.zeros(input_length, encoder.hidden_size)\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "   \n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length-1):\n",
    "\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[:,ei:(ei+1),:], encoder_hidden)\n",
    "        loss += criterion(encoder_output,input_variable[:,ei+1:(ei+2),:])\n",
    "        encoder_outputs[ei] = encoder_output[0,0]\n",
    "    #get the first prediction\n",
    "    encoder_output, encoder_hidden = encoder(input_variable[:,ei+1:(ei+2),:], encoder_hidden)\n",
    "    decoder_input = encoder_output\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "    oo=encoder_hidden\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "#             print(decoder_hidden.size())\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            \n",
    "            loss += criterion(decoder_output, target_variable[:,di:di+1,:])\n",
    "            decoder_input = target_variable[:,di:di+1,:]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        print('real start')\n",
    "        print(input_variable[:,ei:(ei+1),:])\n",
    "        print('encode start')\n",
    "        print(decoder_input)\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            \n",
    "#             print(decoder_hidden.size())\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            \n",
    "            decoder_input = decoder_output\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "#             print('sizes')\n",
    "#             print(decoder_output.size(),target_variable[:,di:di+1,:].size())\n",
    "#             print('hidden')\n",
    "#             print(decoder_hidden)\n",
    "#             oo=decoder_hidden\n",
    "#             print('pred')\n",
    "#             print(decoder_output)\n",
    "            \n",
    "#             print('truth')\n",
    "#             print(target_variable[:,di:di+1,:])\n",
    "#             print('-'*90)\n",
    "            loss += criterion(decoder_output, target_variable[:,di:di+1,:])\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length,encoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid(input_variable, target_variable, encoder, decoder, criterion):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    input_length = input_variable.size()[1]\n",
    "    target_length = target_variable.size()[1]\n",
    "#     print(target_length)\n",
    "    \n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[:,ei:(ei+1),:], encoder_hidden)\n",
    "    \n",
    "    decoder_input = encoder_output\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "#     use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "#     if use_teacher_forcing:\n",
    "#         # Teacher forcing: Feed the target as the next input\n",
    "#         for di in range(target_length):\n",
    "#             decoder_output, decoder_hidden = decoder(\n",
    "#                 decoder_input, decoder_hidden)\n",
    "#             loss += criterion(decoder_output, target_variable[:,di:di+1,:])\n",
    "#             decoder_input = target_variable[:,di:di+1,:]  # Teacher forcing\n",
    "\n",
    "#     else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "    outputs=[]\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden)\n",
    "\n",
    "        decoder_input = decoder_output\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        outputs.append(decoder_output.squeeze().detach().cpu().numpy())\n",
    "#         print(decoder_output.size(), target_variable[:,di:di+1,:].size())\n",
    "        loss += criterion(decoder_output, target_variable[:,di:di+1,:])\n",
    "\n",
    "\n",
    "    return (loss.item() / target_length,np.array(outputs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
