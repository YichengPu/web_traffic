{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from util.evaluation import SMAPE\n",
    "%matplotlib inline\n",
    "\n",
    "traffic=pd.read_csv('../data/cl_traffic.csv')\n",
    "\n",
    "traffic=traffic.fillna(0)\n",
    "\n",
    "traffic.head()\n",
    "\n",
    "sample_index=np.random.choice(traffic.index,400,replace=False)\n",
    "sample_series=[]\n",
    "for u in sample_index:\n",
    "#     print('Training...|| {:.2f}'.format(u/tot_len*100)+'%',end='\\r')\n",
    "    sample_series.append(traffic.loc[u][:-4].values)\n",
    "\n",
    "def diff(x,epsilon=1e-3):\n",
    "    return((x[1:]-x[:-1])/(x[:-1]+epsilon))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_and_clean(sample_series,train_start,train_end,test_len):\n",
    "    clean_series=[]\n",
    "    test_series=[]\n",
    "    for index in range(len(sample_series)):\n",
    "        c=np.array(sample_series[index][train_start:train_end])\n",
    "        test_series.append(sample_series[index][train_end:(train_end+test_len)])\n",
    "        std=np.std(c)\n",
    "        mean=np.mean(c)\n",
    "        c[(c-np.mean(c))>2*std]=mean+2*std\n",
    "        c[(c-np.mean(c))<-2*std]=mean-2*std\n",
    "        clean_series.append(c)\n",
    "    return (clean_series,test_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalize_X(clean_series):\n",
    "Krikor Zohrab,\n",
    "    recover_dic={}\n",
    "    scaled_series=[]\n",
    "    for i in range(len(clean_series)):\n",
    "        if np.sum(clean_series[i])==0:\n",
    "            scaled_series.append(np.zeros_like(clean_series[i]))\n",
    "            recover_dic[i]=(0,0)\n",
    "        else:\n",
    "            std=np.std(clean_series[i])\n",
    "            biased_mean=np.mean(clean_series[i])-3*std\n",
    "\n",
    "            recover_dic[i]=(std,biased_mean)\n",
    "            new_series=clean_series[i]-biased_mean\n",
    "            new_series[new_series<0]=0\n",
    "            new_series=new_series/(6*std)\n",
    "            new_series[new_series>1]=1\n",
    "            scaled_series.append(new_series)\n",
    "    return (scaled_series,recover_dic)\n",
    "\n",
    "\n",
    "def normalize_Y(clean_series,recover_dic):\n",
    "    scaled_series=[]\n",
    "    for i in range(len(clean_series)):\n",
    "        (std,biased_mean) = recover_dic[i]\n",
    "        \n",
    "        if std==0:\n",
    "            # ignore all zero cases\n",
    "#             print(clean_series[i])\n",
    "            scaled_series.append(np.zeros_like(clean_series[i]))\n",
    "\n",
    "        else:\n",
    "            \n",
    "\n",
    "            new_series=clean_series[i]-biased_mean\n",
    "            new_series[new_series<0]=0\n",
    "            new_series=new_series/(6*std)\n",
    "            new_series[new_series>1]=1\n",
    "            scaled_series.append(new_series)\n",
    "    return (scaled_series)\n",
    "\n",
    "def recover(scaled_series,recover_dic):\n",
    "    recovered_series=[]\n",
    "    for i in range(len(scaled_series)):\n",
    "        std,biased_mean=recover_dic[i]\n",
    "        new_series=scaled_series[i]*(6*float(std))+biased_mean\n",
    "        recovered_series.append(new_series)\n",
    "    return recovered_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode_start=0\n",
    "# encode_end=150\n",
    "# decode_len=63\n",
    "\n",
    "# clean_series,decode_series = split_and_clean(sample_series,encode_start,encode_end,decode_len)\n",
    "\n",
    "\n",
    "# train_x=clean_series\n",
    "# train_y=decode_series\n",
    "\n",
    "# encode_start=200\n",
    "# encode_end=350\n",
    "# decode_len=63\n",
    "\n",
    "\n",
    "# clean_series,decode_series = split_and_clean(sample_series,encode_start,encode_end,decode_len)\n",
    "\n",
    "# test_x=clean_series\n",
    "# test_y=decode_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encode_start=0\n",
    "encode_end=150\n",
    "decode_len=63\n",
    "\n",
    "clean_series,decode_series = split_and_clean(sample_series,encode_start,encode_end,decode_len)\n",
    "train_x,train_dic = normalize_X(clean_series)\n",
    "train_y = normalize_Y(decode_series,train_dic)\n",
    "\n",
    "\n",
    "encode_start=200\n",
    "encode_end=350\n",
    "decode_len=63\n",
    "\n",
    "\n",
    "clean_series,decode_series = split_and_clean(sample_series,encode_start,encode_end,decode_len)\n",
    "\n",
    "test_x,test_dic = normalize_X(clean_series)\n",
    "test_y = normalize_Y(decode_series,test_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def X_loader(x,batchsize=10):\n",
    "    batch=0\n",
    "    x=np.array(x,dtype=np.float32)\n",
    "#     x=np.log(x+1)\n",
    "    \n",
    "    while batch<(len(x) // batchsize):\n",
    "        \n",
    "        data=x[batch*batchsize:(batch+1)*batchsize,:]\n",
    "        tensor=torch.FloatTensor(np.array(data, dtype=float))\n",
    "        tensor=tensor.unsqueeze(2).cuda()\n",
    "#         tensor=tensor.repeat(1,1,25)\n",
    "        yield(tensor)\n",
    "        batch+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def Y_loader(y,batchsize=10):\n",
    "    batch=0\n",
    "    y=np.array(y,dtype=np.float32)\n",
    "#     y=np.log(y+1)\n",
    "    \n",
    "    while batch<(len(y) // batchsize):\n",
    "        \n",
    "        data=y[batch*batchsize:(batch+1)*batchsize,:]\n",
    "        tensor=torch.FloatTensor(np.array(data, dtype=float))\n",
    "        tensor=tensor.unsqueeze(2).cuda()\n",
    "\n",
    "        yield(tensor)\n",
    "        batch+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for name, param in decoder.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SMAPE(true,predicted):\n",
    "    true=true.squeeze()\n",
    "    predicted=predicted.squeeze()\n",
    "#     true=torch.exp(true)-1\n",
    "#     predicted=torch.exp(predicted)-1\n",
    "    epsilon = 0.1\n",
    "    summ = torch.abs(true) + torch.abs(predicted) + epsilon\n",
    "    smape = torch.abs(predicted - true) / summ * 2.0\n",
    "    return torch.mean(smape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainx=X_loader(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=next(trainx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4175],\n",
       "        [ 0.2017],\n",
       "        [ 0.3586],\n",
       "        [ 0.3742],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.8314],\n",
       "        [ 0.4693],\n",
       "        [ 0.6712],\n",
       "        [ 0.4315]], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from numpy import random as random\n",
    "epoch=10\n",
    "indicator=5\n",
    "\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha=0.99, \\\n",
    "#     eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0)\n",
    "input_size=1\n",
    "hidden_size=5\n",
    "output_size=1\n",
    "lr=0.01\n",
    "batch_size=5\n",
    "encoder=EncoderRNN(input_size,hidden_size,output_size).cuda() if use_cuda else EncoderRNN(1,hidden_size)\n",
    "decoder=DecoderRNN(input_size,hidden_size,output_size).cuda() if use_cuda else DecoderRNN(1,hidden_size)\n",
    "teacher_forcing_ratio = 0.2\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=lr)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5536],\n",
      "        [ 0.3381],\n",
      "        [ 0.3361],\n",
      "        [ 0.5930],\n",
      "        [ 0.4324]], device='cuda:0')\n",
      "tensor([[[-0.6389, -0.0151, -0.1930, -0.1432,  0.1996]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.4580],\n",
      "        [ 0.2918],\n",
      "        [ 0.3794],\n",
      "        [ 0.5881],\n",
      "        [ 0.4126]], device='cuda:0')\n",
      "tensor([[[-0.5538,  0.1198, -0.1429,  0.0114,  0.3622]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.3342],\n",
      "        [ 0.3923],\n",
      "        [ 0.6361],\n",
      "        [ 0.6717],\n",
      "        [ 1.0000]], device='cuda:0')\n",
      "tensor([[[-0.6392,  0.1696, -0.2542, -0.1006,  0.3804]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.3333],\n",
      "        [ 0.4039],\n",
      "        [ 0.4048],\n",
      "        [ 0.5843],\n",
      "        [ 0.3846]], device='cuda:0')\n",
      "tensor([[[-0.5549,  0.1051, -0.1395, -0.0024,  0.3384]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.4691],\n",
      "        [ 0.4606],\n",
      "        [ 0.5831],\n",
      "        [ 0.9657],\n",
      "        [ 0.2962]], device='cuda:0')\n",
      "tensor([[[-0.5626,  0.1354, -0.1490, -0.0188,  0.3704]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.2347],\n",
      "        [ 1.0000],\n",
      "        [ 0.4577],\n",
      "        [ 0.4161],\n",
      "        [ 0.4529]], device='cuda:0')\n",
      "tensor([[[-0.5727,  0.0821, -0.1500, -0.0473,  0.2938]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "Epoch: 0; iterations: 5; encoding Loss: 0.2560938764738556;decoding Loss: 0.3437247382269965\n",
      "\n",
      "tensor([[ 0.3816],\n",
      "        [ 0.3208],\n",
      "        [ 0.7553],\n",
      "        [ 0.2210],\n",
      "        [ 0.5110]], device='cuda:0')\n",
      "tensor([[[-0.5299,  0.1466, -0.1290,  0.0391,  0.3827]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.4428],\n",
      "        [ 0.4139],\n",
      "        [ 0.8982],\n",
      "        [ 0.5303],\n",
      "        [ 0.5820]], device='cuda:0')\n",
      "tensor([[[-0.5831,  0.1132, -0.1737, -0.0665,  0.3100]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.5357],\n",
      "        [ 0.4266],\n",
      "        [ 0.4570],\n",
      "        [ 0.5374],\n",
      "        [ 0.5352]], device='cuda:0')\n",
      "tensor([[[-0.5421,  0.1410, -0.1444,  0.0069,  0.3567]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.4993],\n",
      "        [ 0.4865],\n",
      "        [ 0.8336],\n",
      "        [ 0.0000],\n",
      "        [ 0.4200]], device='cuda:0')\n",
      "tensor([[[-0.5202,  0.0802, -0.1176, -0.0057,  0.2698]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 1.0000],\n",
      "        [ 0.5233],\n",
      "        [ 0.4095],\n",
      "        [ 0.7248],\n",
      "        [ 0.4097]], device='cuda:0')\n",
      "tensor([[[-0.5194,  0.1548, -0.1252,  0.0256,  0.3717]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "Epoch: 0; iterations: 10; encoding Loss: 0.2767217597705406;decoding Loss: 0.284688104901995\n",
      "\n",
      "tensor([[ 0.6000],\n",
      "        [ 0.8190],\n",
      "        [ 0.6568],\n",
      "        [ 0.4121],\n",
      "        [ 0.4936]], device='cuda:0')\n",
      "tensor([[[-0.5557,  0.0734, -0.1535, -0.0785,  0.2332]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.2710],\n",
      "        [ 0.0000],\n",
      "        [ 0.5904],\n",
      "        [ 0.6903],\n",
      "        [ 0.4268]], device='cuda:0')\n",
      "tensor([[[-0.4892,  0.1472, -0.1218,  0.0375,  0.3132]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.3809],\n",
      "        [ 0.6352],\n",
      "        [ 0.5850],\n",
      "        [ 0.6619],\n",
      "        [ 0.8657]], device='cuda:0')\n",
      "tensor([[[-0.5692,  0.1574, -0.2014, -0.0894,  0.2790]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.3527],\n",
      "        [ 0.7848],\n",
      "        [ 0.5654],\n",
      "        [ 0.4863],\n",
      "        [ 0.3982]], device='cuda:0')\n",
      "tensor([[[-0.5096,  0.0934, -0.1260, -0.0249,  0.2381]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.4724],\n",
      "        [ 0.6650],\n",
      "        [ 0.0000],\n",
      "        [ 0.4533],\n",
      "        [ 0.4327]], device='cuda:0')\n",
      "tensor([[[-0.4370,  0.1555, -0.0856,  0.0994,  0.3208]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "Epoch: 0; iterations: 15; encoding Loss: 0.32289738751097813;decoding Loss: 0.3655662476070344\n",
      "\n",
      "tensor([[ 0.5159],\n",
      "        [ 0.5652],\n",
      "        [ 0.3442],\n",
      "        [ 0.4001],\n",
      "        [ 0.4000]], device='cuda:0')\n",
      "tensor([[[-0.4812,  0.0668, -0.1214, -0.0335,  0.1416]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.6481],\n",
      "        [ 0.3665],\n",
      "        [ 0.2704],\n",
      "        [ 0.7072],\n",
      "        [ 0.6046]], device='cuda:0')\n",
      "tensor([[[-0.4580,  0.1519, -0.1331,  0.0109,  0.2223]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.3263],\n",
      "        [ 0.7039],\n",
      "        [ 0.3787],\n",
      "        [ 1.0000],\n",
      "        [ 0.5088]], device='cuda:0')\n",
      "tensor([[[-0.4827,  0.1374, -0.1441, -0.0434,  0.1951]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.8245],\n",
      "        [ 0.5367],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.7522]], device='cuda:0')\n",
      "tensor([[[-0.4254,  0.1409, -0.1204,  0.0317,  0.1809]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.4887],\n",
      "        [ 0.5204],\n",
      "        [ 0.4618],\n",
      "        [ 0.4930],\n",
      "        [ 0.6166]], device='cuda:0')\n",
      "tensor([[[-0.4403,  0.1571, -0.1175,  0.0292,  0.2350]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "Epoch: 0; iterations: 20; encoding Loss: 0.33557070533701233;decoding Loss: 0.37252873011997767\n",
      "\n",
      "tensor([[ 0.4508],\n",
      "        [ 0.4110],\n",
      "        [ 0.4724],\n",
      "        [ 0.1854],\n",
      "        [ 0.3474]], device='cuda:0')\n",
      "tensor([[[-0.4186,  0.0729, -0.0933,  0.0138,  0.1143]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.9026],\n",
      "        [ 0.7566],\n",
      "        [ 0.2850],\n",
      "        [ 0.4168],\n",
      "        [ 0.7416]], device='cuda:0')\n",
      "tensor([[[-0.4192,  0.1660, -0.1224,  0.0189,  0.2027]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.3791],\n",
      "        [ 0.4932],\n",
      "        [ 0.4336],\n",
      "        [ 0.3180],\n",
      "        [ 0.4547]], device='cuda:0')\n",
      "tensor([[[-0.3913,  0.1119, -0.0928,  0.0361,  0.1326]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.5889],\n",
      "        [ 0.3469],\n",
      "        [ 0.6097],\n",
      "        [ 0.3077],\n",
      "        [ 0.3716]], device='cuda:0')\n",
      "tensor([[[-0.3495,  0.1318, -0.0595,  0.1006,  0.1960]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.4872],\n",
      "        [ 0.6205],\n",
      "        [ 0.3651],\n",
      "        [ 0.5341],\n",
      "        [ 0.0000]], device='cuda:0')\n",
      "tensor([[[-0.3399,  0.0672, -0.0451,  0.0688,  0.1176]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "Epoch: 0; iterations: 25; encoding Loss: 0.27544863912083156;decoding Loss: 0.34637528374081566\n",
      "\n",
      "tensor([[ 0.6476],\n",
      "        [ 0.5500],\n",
      "        [ 0.5391],\n",
      "        [ 0.4164],\n",
      "        [ 0.5321]], device='cuda:0')\n",
      "tensor([[[-0.3737,  0.1343, -0.0923,  0.0365,  0.1459]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.4277],\n",
      "        [ 0.4625],\n",
      "        [ 0.0000],\n",
      "        [ 0.8063],\n",
      "        [ 0.4198]], device='cuda:0')\n",
      "tensor([[[-0.3871,  0.1169, -0.1069, -0.0025,  0.0762]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4337],\n",
      "        [ 0.4685],\n",
      "        [ 0.9363],\n",
      "        [ 0.0000],\n",
      "        [ 0.3851]], device='cuda:0')\n",
      "tensor([[[-0.2992,  0.1319, -0.0417,  0.1216,  0.1612]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.4946],\n",
      "        [ 0.0000],\n",
      "        [ 0.3286],\n",
      "        [ 0.4650],\n",
      "        [ 0.3830]], device='cuda:0')\n",
      "tensor([[[-0.3458,  0.1041, -0.0832,  0.0349,  0.0581]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.5202],\n",
      "        [ 0.4309],\n",
      "        [ 0.4389],\n",
      "        [ 0.5238],\n",
      "        [ 0.7230]], device='cuda:0')\n",
      "tensor([[[-0.3889,  0.1450, -0.1281, -0.0324,  0.0747]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "Epoch: 0; iterations: 30; encoding Loss: 0.38535396396713767;decoding Loss: 0.4521496242947049\n",
      "\n",
      "tensor([[ 0.5442],\n",
      "        [ 0.3689],\n",
      "        [ 0.4218],\n",
      "        [ 0.4406],\n",
      "        [ 0.5725]], device='cuda:0')\n",
      "tensor([[[-0.3621,  0.1280, -0.1023,  0.0043,  0.0726]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.4161],\n",
      "        [ 0.4731],\n",
      "        [ 0.5366],\n",
      "        [ 0.4900],\n",
      "        [ 0.4983]], device='cuda:0')\n",
      "tensor([[[-0.3659,  0.1180, -0.0983, -0.0040,  0.0702]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.4411],\n",
      "        [ 0.4015],\n",
      "        [ 0.3865],\n",
      "        [ 0.3446],\n",
      "        [ 0.0000]], device='cuda:0')\n",
      "tensor([[[-0.2350,  0.0919,  0.0034,  0.1754,  0.1344]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.6611],\n",
      "        [ 0.5324],\n",
      "        [ 0.4917],\n",
      "        [ 0.6420],\n",
      "        [ 0.3950]], device='cuda:0')\n",
      "tensor([[[-0.3426,  0.1216, -0.0770,  0.0242,  0.0939]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.5158],\n",
      "        [ 0.8524],\n",
      "        [ 0.0000],\n",
      "        [ 0.4328],\n",
      "        [ 0.3294]], device='cuda:0')\n",
      "tensor([[[-0.3227,  0.1010, -0.0650,  0.0427,  0.0644]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "Epoch: 0; iterations: 35; encoding Loss: 0.32328892394200265;decoding Loss: 0.35488697839161704\n",
      "\n",
      "tensor([[ 0.5004],\n",
      "        [ 0.3234],\n",
      "        [ 0.4806],\n",
      "        [ 0.8592],\n",
      "        [ 0.0000]], device='cuda:0')\n",
      "tensor([[[-0.2404,  0.1205, -0.0056,  0.1419,  0.1494]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.3287],\n",
      "        [ 0.4120],\n",
      "        [ 0.4861],\n",
      "        [ 0.4576],\n",
      "        [ 0.6563]], device='cuda:0')\n",
      "tensor([[[-0.4127,  0.1041, -0.1558, -0.1471, -0.0635]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.0000],\n",
      "        [ 0.5820],\n",
      "        [ 0.5898],\n",
      "        [ 0.5200],\n",
      "        [ 0.3382]], device='cuda:0')\n",
      "tensor([[[-0.2818,  0.1028, -0.0546,  0.0426,  0.0473]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.5590],\n",
      "        [ 0.8708],\n",
      "        [ 0.3925],\n",
      "        [ 0.4472],\n",
      "        [ 0.8075]], device='cuda:0')\n",
      "tensor([[[-0.3458,  0.1421, -0.1198, -0.0761,  0.0190]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.3819],\n",
      "        [ 0.9693],\n",
      "        [ 0.7403],\n",
      "        [ 0.4813],\n",
      "        [ 0.3171]], device='cuda:0')\n",
      "tensor([[[-0.3180,  0.0822, -0.0676, -0.0199,  0.0382]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "Epoch: 0; iterations: 40; encoding Loss: 0.3361810876219064;decoding Loss: 0.37204771496000744\n",
      "\n",
      "tensor([[ 0.5930],\n",
      "        [ 0.4271],\n",
      "        [ 0.4128],\n",
      "        [ 0.3844],\n",
      "        [ 0.6869]], device='cuda:0')\n",
      "tensor([[[-0.3021,  0.1359, -0.0931, -0.0229,  0.0082]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.5258],\n",
      "        [ 0.5429],\n",
      "        [ 0.5951],\n",
      "        [ 0.5500],\n",
      "        [ 0.3643]], device='cuda:0')\n",
      "tensor([[[-0.2915,  0.0984, -0.0603,  0.0060,  0.0339]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.4565],\n",
      "        [ 0.3872],\n",
      "        [ 0.4402],\n",
      "        [ 0.4806],\n",
      "        [ 0.5306]], device='cuda:0')\n",
      "tensor([[[-0.2946,  0.1193, -0.0781, -0.0122,  0.0048]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.3044],\n",
      "        [ 0.5460],\n",
      "        [ 0.3915],\n",
      "        [ 0.4571],\n",
      "        [ 0.4426]], device='cuda:0')\n",
      "tensor([[[-0.3247,  0.0976, -0.0952, -0.0582, -0.0382]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.5695],\n",
      "        [ 1.0000],\n",
      "        [ 0.8221],\n",
      "        [ 0.4540],\n",
      "        [ 0.0000]], device='cuda:0')\n",
      "tensor([[[-0.2163,  0.0654,  0.0066,  0.0998,  0.0985]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "Epoch: 0; iterations: 45; encoding Loss: 0.25847683848950687;decoding Loss: 0.33064072321331694\n",
      "\n",
      "tensor([[ 0.4531],\n",
      "        [ 0.4236],\n",
      "        [ 0.6910],\n",
      "        [ 0.3538],\n",
      "        [ 0.4776]], device='cuda:0')\n",
      "tensor([[[-0.3094,  0.1022, -0.0852, -0.0524, -0.0272]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.4353],\n",
      "        [ 0.7077],\n",
      "        [ 0.4335],\n",
      "        [ 0.6184],\n",
      "        [ 0.4087]], device='cuda:0')\n",
      "tensor([[[-0.2340,  0.1158, -0.0287,  0.0531,  0.0545]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.5717],\n",
      "        [ 0.4550],\n",
      "        [ 0.6863],\n",
      "        [ 0.3631],\n",
      "        [ 0.5526]], device='cuda:0')\n",
      "tensor([[[-0.3360,  0.0987, -0.1149, -0.1367, -0.0818]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.9631],\n",
      "        [ 0.6406],\n",
      "        [ 0.4729],\n",
      "        [ 0.9273],\n",
      "        [ 0.5333]], device='cuda:0')\n",
      "tensor([[[-0.3203,  0.1053, -0.0971, -0.1219, -0.0347]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.5023],\n",
      "        [ 0.6519],\n",
      "        [ 0.4653],\n",
      "        [ 0.6103],\n",
      "        [ 1.0000]], device='cuda:0')\n",
      "tensor([[[-0.3263,  0.1600, -0.1454, -0.1871, -0.0845]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "Epoch: 0; iterations: 50; encoding Loss: 0.2188911105162345;decoding Loss: 0.2802957504514664\n",
      "\n",
      "tensor([[ 0.5923],\n",
      "        [ 0.2754],\n",
      "        [ 1.0000],\n",
      "        [ 0.6191],\n",
      "        [ 0.3876]], device='cuda:0')\n",
      "tensor([[[-0.2717,  0.0911, -0.0593, -0.0484, -0.0113]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.3728],\n",
      "        [ 0.3138],\n",
      "        [ 0.4937],\n",
      "        [ 0.4454],\n",
      "        [ 0.3913]], device='cuda:0')\n",
      "tensor([[[-0.1932,  0.1045, -0.0257,  0.0568, -0.0060]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.3454],\n",
      "        [ 0.5488],\n",
      "        [ 0.5265],\n",
      "        [ 0.3589],\n",
      "        [ 0.0000]], device='cuda:0')\n",
      "tensor([[[-0.1485,  0.0619,  0.0202,  0.1349,  0.0334]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.6335],\n",
      "        [ 0.5119],\n",
      "        [ 0.4088],\n",
      "        [ 0.3721],\n",
      "        [ 0.3907]], device='cuda:0')\n",
      "tensor([[[-0.1846,  0.1008, -0.0196,  0.0583, -0.0012]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.5301],\n",
      "        [ 0.3532],\n",
      "        [ 0.3627],\n",
      "        [ 0.3973],\n",
      "        [ 0.8805]], device='cuda:0')\n",
      "tensor([[[-0.3232,  0.1508, -0.1536, -0.2224, -0.1549]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "Epoch: 0; iterations: 55; encoding Loss: 0.2779470405322593;decoding Loss: 0.35455726744636656\n",
      "\n",
      "tensor([[ 0.2365],\n",
      "        [ 0.3684],\n",
      "        [ 0.0000],\n",
      "        [ 0.4479],\n",
      "        [ 0.0000]], device='cuda:0')\n",
      "tensor([[[-0.0945,  0.0760,  0.0372,  0.1889,  0.0144]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7846],\n",
      "        [ 0.4016],\n",
      "        [ 0.5042],\n",
      "        [ 0.3967],\n",
      "        [ 0.7720]], device='cuda:0')\n",
      "tensor([[[-0.2586,  0.1398, -0.0940, -0.1239, -0.0842]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.4670],\n",
      "        [ 0.0000],\n",
      "        [ 0.2270],\n",
      "        [ 0.3782],\n",
      "        [ 0.3617]], device='cuda:0')\n",
      "tensor([[[-0.1760,  0.1085, -0.0324,  0.0362, -0.0693]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.6712],\n",
      "        [ 0.4412],\n",
      "        [ 0.3153],\n",
      "        [ 0.4139],\n",
      "        [ 0.7529]], device='cuda:0')\n",
      "tensor([[[-0.2451,  0.1439, -0.0896, -0.1204, -0.0970]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.2838],\n",
      "        [ 0.2646],\n",
      "        [ 0.4782],\n",
      "        [ 0.5812],\n",
      "        [ 0.6531]], device='cuda:0')\n",
      "tensor([[[-0.2325,  0.1395, -0.0713, -0.0912, -0.0923]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "Epoch: 0; iterations: 60; encoding Loss: 0.3722555813373335;decoding Loss: 0.43042318858797585\n",
      "\n",
      "tensor([[ 0.0000],\n",
      "        [ 0.4877],\n",
      "        [ 0.4979],\n",
      "        [ 0.5639],\n",
      "        [ 0.7091]], device='cuda:0')\n",
      "tensor([[[-0.2708,  0.1448, -0.1021, -0.1716, -0.1357]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.3875],\n",
      "        [ 0.7013],\n",
      "        [ 0.3717],\n",
      "        [ 0.4712],\n",
      "        [ 0.0000]], device='cuda:0')\n",
      "tensor([[[-0.0791,  0.0735,  0.0611,  0.1843,  0.0434]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.4497],\n",
      "        [ 0.9712],\n",
      "        [ 0.4239],\n",
      "        [ 0.3531],\n",
      "        [ 0.4769]], device='cuda:0')\n",
      "tensor([[[-0.2085,  0.1119, -0.0441, -0.0563, -0.0712]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.3851],\n",
      "        [ 0.0000],\n",
      "        [ 0.3217],\n",
      "        [ 0.4382],\n",
      "        [ 0.3234]], device='cuda:0')\n",
      "tensor([[[-0.0674,  0.1236,  0.0455,  0.1545, -0.0116]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n",
      "tensor([[ 0.9516],\n",
      "        [ 0.4645],\n",
      "        [ 0.3733],\n",
      "        [ 0.3994],\n",
      "        [ 0.5652]], device='cuda:0')\n",
      "tensor([[[-0.2420,  0.1191, -0.0812, -0.1603, -0.1281]]], device='cuda:0')\n",
      "__________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-96b8e9cf50f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0me_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m                   \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSMAPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mrunning_loss_e\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0me_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mrunning_loss_d\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-314e51027f60>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mloss_decoding\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_encoding\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mloss_decoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    trainx=X_loader(train_x,batch_size)\n",
    "    trainy=Y_loader(train_y,batch_size)\n",
    "    running_loss_e = 0.0\n",
    "    running_loss_d = 0.0\n",
    "#     validation(test_x,test_y)\n",
    "    for j,X_batch in enumerate(trainx):\n",
    "        #Parse loaded batch\n",
    "        x=X_batch\n",
    "        y=next(trainy)\n",
    "        e_loss,d_loss=train(x, y, encoder, decoder, encoder_optimizer, \\\n",
    "                  decoder_optimizer, SMAPE)\n",
    "        running_loss_e += e_loss\n",
    "        running_loss_d += d_loss\n",
    "        if (j>0) and (j % indicator == 0):\n",
    "            print(\"Epoch: {}; iterations: {}; encoding Loss: {};decoding Loss: {}\\n\".format(i, j, \\\n",
    "                                running_loss_e / indicator,running_loss_d / indicator))\n",
    "            running_loss_e = 0.0\n",
    "            running_loss_d = 0.0\n",
    "    _,_,score = valid_iter(test_x, test_y)\n",
    "    print(\"Validation! Epoch: {}; Loss: {}\\n\".format(i, np.mean(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\r"
     ]
    }
   ],
   "source": [
    "preds,targets,scores=valid_iter(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from util.evaluation import SMAPE as cpu_SMAPE\n",
    "# scores=[]\n",
    "# for (t,p) in zip(truth,pred):\n",
    "#     scores.append(cpu_SMAPE(t,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds=recover(preds,test_dic)\n",
    "recovered_test_x=recover(test_x,test_dic)\n",
    "targets=recover(targets,test_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5901312545699322"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util.evaluation import SMAPE as cpu_SMAPE\n",
    "mean_scores=[]\n",
    "\n",
    "\n",
    "for ID in range(4000):\n",
    "\n",
    "    pred=preds[ID]\n",
    "    truth=targets[ID]\n",
    "    scores=[]\n",
    "    for (t,p) in zip(truth,pred):\n",
    "        scores.append(cpu_SMAPE(t,p))\n",
    "\n",
    "    mean_scores.append(np.mean(scores))\n",
    "np.mean(mean_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82.33819 81.93101 82.04946 82.04807 82.04807 82.04807 82.04807 82.04807\n",
      " 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807\n",
      " 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807\n",
      " 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807\n",
      " 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807\n",
      " 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807\n",
      " 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807\n",
      " 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807 82.04807]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f371ec41b00>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noVcURYk5KvSKoigxR4VeURQl5vwfJnZF1csb7RgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f371ec5fb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ID=70\n",
    "# source=sample_series[ID][encode_start:encode_end]\n",
    "source=recovered_test_x[ID]\n",
    "pred=preds[ID]\n",
    "truth=targets[ID]\n",
    "print(pred)\n",
    "# for i in range(10):\n",
    "plt.figure()\n",
    "plt.plot(np.arange(encode_start,encode_end),source,color='g',label='history')\n",
    "plt.plot(np.arange(encode_end,encode_end+decode_len),pred,color='r',label='prediction')\n",
    "plt.plot(np.arange(encode_end,encode_end+decode_len),truth,color='b',label='truth')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid_iter(test_x,test_y):\n",
    "    testx=X_loader(test_x)\n",
    "    testy=Y_loader(test_y)\n",
    "\n",
    "    preds=[]\n",
    "    targets=[]\n",
    "\n",
    "    scores=[]\n",
    "    for j,X_batch in enumerate(testx):\n",
    "        #Parse loaded batch\n",
    "        print(j,end='\\r')\n",
    "        target=next(testy)\n",
    "        score,out = valid(X_batch, target, encoder, decoder, SMAPE)\n",
    "        out=out.T\n",
    "        scores.append(score)\n",
    "        target=target.squeeze().detach().cpu().numpy()\n",
    "        if j ==0:\n",
    "            preds=out\n",
    "            targets=target\n",
    "        else:\n",
    "            preds=np.concatenate((preds,out),axis=0)\n",
    "            targets=np.concatenate((targets,target),axis=0)\n",
    "    return (preds,targets,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda=True\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,output_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, input, hidden):\n",
    "\n",
    "        output, hidden = self.gru(input, hidden)\n",
    "        output = torch.sigmoid(self.out(output))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        \n",
    "#         nn.init.xavier_normal_(self.out)\n",
    "        paras= nn.init.xavier_normal_(torch.empty(1,1,self.hidden_size)).cuda() if use_cuda else \\\n",
    "                nn.init.xavier_normal_(torch.empty(1,1,self.hidden_size))\n",
    "        return paras\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size,hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "\n",
    "        output, hidden = self.gru(input, hidden)\n",
    "        output =  torch.sigmoid(self.out(output))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        paras= nn.init.xavier_normal_(torch.empty(1,1,self.hidden_size)).cuda() if use_cuda else \\\n",
    "                nn.init.xavier_normal_(torch.empty(1,1,self.hidden_size))\n",
    "        return paras\n",
    "\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, \\\n",
    "          decoder_optimizer, criterion):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[1]\n",
    "    target_length = target_variable.size()[1]\n",
    "    \n",
    "    encoder_outputs = torch.zeros(input_length, encoder.hidden_size)\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "   \n",
    "    loss_encoding = 0\n",
    "\n",
    "    for ei in range(input_length-1):\n",
    "\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[:,ei:(ei+1),:], encoder_hidden)\n",
    "        loss_encoding += criterion(encoder_output.squeeze(),input_variable[:,ei+1:(ei+2),:].squeeze())\n",
    "        encoder_outputs[ei] = encoder_output[0,0]\n",
    "#     print('-'*90)\n",
    "#     print('pred')\n",
    "#     print(encoder_output.size())\n",
    "#     print(encoder_output)\n",
    "#     print('target')\n",
    "#     print(input_variable[:,ei+1:(ei+2),:].size())\n",
    "#     print(input_variable[:,ei+1:(ei+2),:])\n",
    "#     print(criterion(encoder_output.squeeze(),input_variable[:,ei+1:(ei+2),:].squeeze()))\n",
    "#     print('-'*90)\n",
    "    #get the first prediction\n",
    "    encoder_output, encoder_hidden = encoder(input_variable[:,ei+1:(ei+2),:], encoder_hidden)\n",
    "    decoder_input = encoder_output\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "    print(input_variable[:,-1,:])\n",
    "    print(decoder_hidden)\n",
    "    print('_'*90)\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    loss_decoding=0\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "#             print(decoder_hidden.size())\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            \n",
    "            loss_decoding += criterion(decoder_output.squeeze(), target_variable[:,di:di+1,:].squeeze())\n",
    "            decoder_input = target_variable[:,di:di+1,:]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "#         print('real start')\n",
    "#         print(input_variable[:,ei:(ei+1),:])\n",
    "#         print('encode start')\n",
    "#         print(decoder_input)\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            \n",
    "#             print(decoder_hidden.size())\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            \n",
    "            decoder_input = decoder_output\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "#             print('sizes')\n",
    "#             print(decoder_output.size(),target_variable[:,di:di+1,:].size())\n",
    "#             print('pred')\n",
    "#             print(decoder_output)\n",
    "#             print('truth')\n",
    "#             print(target_variable[:,di:di+1,:])\n",
    "#             print('-'*90)\n",
    "            loss_decoding += criterion(decoder_output.squeeze(), target_variable[:,di:di+1,:].squeeze())\n",
    "    loss=loss_encoding+loss_decoding\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ((loss_encoding.item() / (input_length-1)),(loss_decoding.item() / target_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid(input_variable, target_variable, encoder, decoder, criterion):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    input_length = input_variable.size()[1]\n",
    "    target_length = target_variable.size()[1]\n",
    "#     print(target_length)\n",
    "    \n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[:,ei:(ei+1),:], encoder_hidden)\n",
    "    \n",
    "    decoder_input = encoder_output\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "#     use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "#     if use_teacher_forcing:\n",
    "#         # Teacher forcing: Feed the target as the next input\n",
    "#         for di in range(target_length):\n",
    "#             decoder_output, decoder_hidden = decoder(\n",
    "#                 decoder_input, decoder_hidden)\n",
    "#             loss += criterion(decoder_output, target_variable[:,di:di+1,:])\n",
    "#             decoder_input = target_variable[:,di:di+1,:]  # Teacher forcing\n",
    "\n",
    "#     else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "    outputs=[]\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden)\n",
    "\n",
    "        decoder_input = decoder_output\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        outputs.append(decoder_output.squeeze().detach().cpu().numpy())\n",
    "#         print(decoder_output.size(), target_variable[:,di:di+1,:].size())\n",
    "        loss += criterion(decoder_output, target_variable[:,di:di+1,:])\n",
    "\n",
    "\n",
    "    return (loss.item() / target_length,np.array(outputs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
